# Вариант реализации STT и обогащения текста с Hugging Face и MedCAT

Документ описывает проработку использования **Hugging Face** (распознавание речи) и **MedCAT** (медицинская NER и связывание с онтологиями) в контексте VET-028 (приватный/альтернативный STT) и обогащения протоколов осмотра.

---

## 1. Роли сервисов

| Сервис | Назначение | Этап в пайплайне |
|--------|------------|------------------|
| **Hugging Face** | Распознавание речи (STT) | Замена/дополнение облачного или «приватного» провайдера |
| **MedCAT** | Извлечение медицинских сущностей из текста (NER + связь с UMLS/SNOMED) | Постобработка после STT, до/вместе с правилами шаблона |

- **STT** даёт текст из аудио; **MedCAT** не заменяет STT, а обогащает уже распознанный текст структурированными сущностями (диагнозы, препараты, процедуры и т.д.).

---

## 2. Hugging Face как провайдер STT

### 2.1. Варианты использования

- **Вариант A — облачный Inference API (Serverless)**  
  Прямые запросы к `https://api-inference.huggingface.co/...` с токеном пользователя. Подходит как ещё один облачный провайдер наравне с Google Speech-to-Text (VET-027).

- **Вариант B — Inference Endpoints (свой инстанс)**  
  Развёртывание своей модели Whisper на Hugging Face Inference Endpoints. По сути это «приватный» STT (VET-028): данные идут на ваш endpoint, а не в общий пул HF.

- **Вариант C — Self-hosted (на своём сервере)**  
  Развернуть Whisper (или другой ASR из Hugging Face) на своём железе и вызывать его по REST. Тогда в приложении это реализуется через существующий `PrivateServerRecognizer` с URL вашего сервера.

В приложении логично реализовать **отдельный провайдер Hugging Face** (варианты A и B с одним и тем же форматом API), а вариант C оставить за текущим приватным провайдером.

### 2.2. Hugging Face Inference API — формат

- **Документация:** [Automatic Speech Recognition — Inference Providers](https://huggingface.co/docs/inference-providers/en/tasks/automatic-speech-recognition).

- **Авторизация:** Personal Access Token с правом «Inference» в заголовке:
  ```http
  Authorization: Bearer hf_xxxxxxxxxxxx
  ```

- **Запрос:**
  - URL: `https://api-inference.huggingface.co/models/openai/whisper-large-v3` (или другой ASR-модель).
  - Метод: `POST`.
  - Тело: аудио как **сырые байты** (binary) с заголовком `Content-Type: audio/flac` или `audio/wav`, либо JSON с полем `inputs` — base64-строка аудио.
  - Опционально в `parameters`: `return_timestamps: true` для получения временных меток.

- **Ответ (упрощённо):**
  ```json
  {
    "text": "распознанный текст",
    "chunks": [
      { "text": "фрагмент", "timestamp": [start, end] }
    ]
  }
  ```

- **Ограничения:** квоты и лимиты по тарифу HF; для продакшена предпочтительны Inference Endpoints (предсказуемая нагрузка и латентность).

### 2.3. Реализация в приложении (HuggingFaceRecognizer)

- **Интерфейс:** реализовать `SpeechRecognizer` (как `CloudRecognizer` и др.).
- **Конфиг:** URL модели (по умолчанию `https://api-inference.huggingface.co/models/openai/whisper-large-v3`) и токен из `AppConfig` / настроек (dart-define или хранилище).
- **Метод `recognize(String audioFilePath)`:**
  - Читать файл, при необходимости конвертировать в поддерживаемый формат (например WAV/FLAC 16 kHz).
  - Отправлять POST с телом = байты аудио или base64 в `inputs`.
  - Парсить ответ и собирать `SttResult`: `text`, при наличии — `timestamps` из `chunks`, `confidence` можно задать по умолчанию или не использовать, `provider: SttProvider.huggingFace` (нужно добавить значение в enum).
- **`isAvailable()`:** true при наличии токена (и при необходимости проверки доступа к модели).
- **Роутер:** в `SttRouter` добавить опциональный `HuggingFaceRecognizer` и в политике Auto включить его после приватного и перед облаком Google (или по приоритету из настроек).

Зависимости: текущие `http`/`dio` достаточны; отдельный пакет для HF не обязателен.

---

## 3. MedCAT как сервис обогащения текста

### 3.1. Назначение

- **MedCAT** (и **MedCATservice**) решают задачу NER+L: находят в тексте медицинские сущности и связывают их с онтологиями (UMLS, SNOMED-CT и т.д.).
- В контексте ветпротоколов: после STT имеем текст анамнеза/осмотра; MedCAT возвращает структурированные сущности (диагнозы, препараты, процедуры, симптомы). Их можно:
  - использовать для автозаполнения полей протокола (маппинг типов сущностей на поля шаблона);
  - показывать как подсказки или уточнения;
  - сохранять в структурированном виде рядом с текстом.

### 3.2. MedCATservice API (архивный, но пригодный для развёртывания)

- Репозиторий: [CogStack/MedCATservice](https://github.com/CogStack/MedCATservice) (архивирован 30.06.2025; код и Docker по-прежнему пригодны для развёртывания).
- Эндпоинты:
  - `GET /api/info` — информация о сервисе и модели.
  - `POST /api/process` — аннотация одного документа.
  - `POST /api/process_bulk` — аннотация списка документов.

**Запрос** `POST /api/process`:
```http
Content-Type: application/json

{
  "content": {
    "text": "Текст для аннотации, например: у пациента подозрение на хроническую почечную недостаточность."
  }
}
```

**Ответ (сокращённо):**
```json
{
  "result": {
    "text": "исходный текст",
    "annotations": {
      "entities": {
        "0": {
          "pretty_name": "Chronic kidney disease",
          "cui": "C0022658",
          "type_ids": ["T047"],
          "types": ["Disease or Syndrome"],
          "source_value": "почечную недостаточность",
          "detected_name": "chronic kidney disease",
          "acc": 0.95,
          "start": 12,
          "end": 35,
          "meta_anns": {
            "Status": { "value": "Affirmed", "confidence": 0.99 }
          }
        }
      }
    }
  },
  "success": true,
  "medcat_info": {
    "service_app_name": "MedCAT",
    "service_language": "ru",
    "service_model": "..."
  }
}
```

- Модели для русского языка нужно отдельно подбирать или дообучать; в документации упоминаются английские модели (MedMentions). Для ветеринарии потребуется либо русская модель, либо ветспецифичный дообученный вариант.

### 3.3. Интеграция MedCAT в приложение

- **Новый сервис (не провайдер STT):** например, `MedCatAnnotationService` в `lib/features/speech/` или отдельном модуле `lib/features/medcat/`.
- **Метод:** `Future<MedCatResult> annotate(String text)`:
  - POST на настраиваемый base URL (например `http(s)://host:5000/api/process`) с телом `{"content":{"text": text}}`.
  - Таймаут 30–60 сек (аннотация может быть тяжёлой).
  - Парсинг ответа в доменную модель: список сущностей с `cui`, `pretty_name`, `types`, `source_value`, `start`/`end`, `meta_anns` и т.д.
- **Конфиг:** URL MedCAT-сервиса, опционально токен (если позже добавят авторизацию). Включение/выключение обогащения через настройки.
- **Точка вызова:** после получения текста от STT в `examination_create_page` (или в общем пайплайне):
  1. `router.transcribe(audioPath)` → `SttResult.text`;
  2. опционально `medCatAnnotationService.annotate(sttResult.text)` → сущности;
  3. `SttExtractionService.extractFields(template, sttResult.text, ...)` — как сейчас;
  4. объединение: приоритет правилам шаблона, сущности MedCAT использовать для дополнения полей (по маппингу типов на ключи полей) или для отображения подсказок.

Маппинг типов MedCAT (например `Disease or Syndrome`, `Diagnostic Procedure`) на поля шаблона можно задать в настройках шаблона или в отдельной конфигурации (например, «тип сущности → ключ поля»).

### 3.4. Ограничения и риски MedCAT

- Репозитории MedCAT/MedCATservice архивированы — новые фичи от сообщества маловероятны; развёртывание и дообучение остаются на стороне команды.
- Для русского и ветеринарной терминологии нужна подходящая модель (русская/ветеринарная или дообучение); «из коробки» в примерах в основном английский и общая медицина.
- Лицензии на SNOMED-CT/UMLS при использовании таких онтологий в моделях — отдельный вопрос.

---

## 4. Сводная архитектура пайплайна

```
[ Аудио ] → [ SttRouter ] → текст (SttResult)
                 │
                 ├─ CloudRecognizer (Google)     — VET-027
                 ├─ HuggingFaceRecognizer       — новый (HF Inference API / Endpoints)
                 ├─ PrivateServerRecognizer     — VET-028 (свой сервер / Whisper)
                 └─ OnDeviceRecognizer           — VET-029 (офлайн)
                 │
                 ▼
            [ Текст ]
                 │
                 ├─ SttExtractionService.extractFields(template, text)  — правила шаблона (как сейчас)
                 └─ MedCatAnnotationService.annotate(text)               — опционально, сущности
                 │
                 ▼
            Объединение: поля формы + сущности MedCAT (маппинг типов → поля, подсказки)
```

---

## 5. План внедрения по шагам

### Фаза 1 — Hugging Face как STT-провайдер

1. Добавить в `SttProvider` значение `huggingFace` (при необходимости переименовать для ясности).
2. Реализовать `HuggingFaceRecognizer` (URL модели, токен, запрос/ответ по спецификации HF ASR).
3. Добавить конфиг (dart-define или настройки): `STT_HF_TOKEN`, опционально URL модели.
4. Зарегистрировать в DI и в `SttRouter`: приоритет после приватного, перед облаком Google (или настраиваемый).
5. Проверить на реальном аудио (в т.ч. русский язык).

### Фаза 2 — MedCAT как опциональное обогащение

1. Описать доменную модель ответа MedCAT (сущность: cui, pretty_name, types, source_value, start, end, meta_anns).
2. Реализовать `MedCatAnnotationService` (HTTP-клиент, парсинг `/api/process`).
3. Конфиг: URL MedCAT-сервиса, флаг «Включить обогащение MedCAT».
4. Вызов из сценария «Распознать» после STT; объединение с `extractFields` и маппинг типов сущностей на поля (конфигурируемый маппинг).
5. При отсутствии своей модели: документировать развёртывание MedCATservice (Docker) и возможность отключения функции в приложении.

### Фаза 3 (опционально)

- Настройки в UI: выбор провайдера STT (Google / Hugging Face / приватный / офлайн), URL и токены, вкл/выкл MedCAT и URL MedCAT.
- Кэширование ответов MedCAT по хэшу текста (чтобы не дергать сервис при повторном открытии того же протокола).

---

## 6. Бесплатное использование медицинских NLP моделей Hugging Face

### Лицензии моделей — да, многие бесплатны

- **Предобученные медицинские NLP модели** на Hugging Face (NER, классификация, NER+L и т.д.) часто распространяются под открытыми лицензиями:
  - **Apache 2.0** — разрешено коммерческое использование, модификация, распространение (с сохранением уведомлений). Пример: семейство **OpenMed** (380+ медицинских NER моделей).
  - **MIT** — аналогично свободное использование.
- Важно каждый раз смотреть **карточку модели** на Hub: вкладка «Model card» или «License». Встречаются модели с ограничениями:
  - **Non-commercial / Research only** — только некоммерческое использование или исследования.
  - **Custom** — нужно читать текст лицензии в репозитории.
- Фильтр по лицензии: [Hugging Face Models — фильтр по license](https://huggingface.co/models). Для коммерческого продукта выбирать модели с Apache 2.0 / MIT или явно разрешённым коммерческим использованием.

### Как использовать «бесплатно»

| Способ | Бесплатно? | Пояснение |
|--------|------------|-----------|
| **Скачать модель и запускать у себя** | ✅ Да | Модели с открытой лицензией можно скачивать и запускать локально или на своём сервере (PyTorch/Transformers, свой API). Никакой платы Hugging Face за инференс нет — только ваши затраты на железо и электричество. |
| **Inference API (Serverless)** | ⚠️ Очень ограниченно | Бесплатный аккаунт получает около **$0.10 в месяц** кредитов. После исчерпания лимита бесплатные пользователи **не могут** продолжать использование (pay-as-you-go только у PRO и выше). Для постоянной нагрузки не подходит. |
| **Inference Endpoints (свой инстанс на HF)** | ❌ Платно | Оплата за время работы инстанса (GPU/CPU). Удобно для «приватного» облачного инференса без своей инфраструктуры. |

Итог: **бесплатно в долгосрочной перспективе** медицинские модели HF можно использовать только так: **скачать веса и запускать инференс у себя** (локально или на своём сервере). Тогда вы платите только за хостинг/электричество, а не за запросы к API.

### OpenMed (пример бесплатных медицинских моделей)

- Проект **OpenMed** на Hugging Face: множество медицинских NER моделей под **Apache 2.0**, бесплатно для коммерческого использования.
- Страница: [OpenMed на Hugging Face](https://huggingface.co/OpenMed); в блоге HF есть посты про [Open Health AI](https://huggingface.co/blog/MaziyarPanahi/open-health-ai) и обзор OpenMed.
- Модели можно скачать через `huggingface_hub` / API Hub и использовать в своём пайплайне (например, заменить или дополнить MedCAT для извлечения сущностей из текста протоколов).

### Рекомендация для вет-ассистента

- Для **обогащения текста** (аналог MedCAT): выбирать медицинские модели с лицензией Apache 2.0 / MIT, **разворачивать инференс у себя** (свой сервер или приватный контейнер) и вызывать его из приложения как «приватный» сервис аннотации — тогда использование остаётся бесплатным (кроме инфраструктуры).
- Для **STT через HF**: бесплатный Inference API даёт лишь символический объём ($0.10/мес); для реальной работы либо платный план / свои кредиты, либо свой сервер с Whisper (офлайн или приватный endpoint).

---

## 7. Ссылки

- [Hugging Face — Automatic Speech Recognition (Inference)](https://huggingface.co/docs/inference-providers/en/tasks/automatic-speech-recognition)
- [Hugging Face — openai/whisper-large-v3](https://huggingface.co/openai/whisper-large-v3)
- [MedCATservice (GitHub)](https://github.com/CogStack/MedCATservice) — REST API, Docker, примеры запросов/ответов
- [MedCAT (документация)](https://medcat.readthedocs.io/)
- [CogStack GATE NLP Service (OpenAPI)](https://github.com/CogStack/gate-nlp-service/) — спецификация API, совместимая с MedCATservice

---

*Документ привязан к артефактам VET-028 (приватный/альтернативный STT) и к идее обогащения протоколов медицинскими сущностями через MedCAT.*
